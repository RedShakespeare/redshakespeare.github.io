{"title":"","date":"2025-12-02T22:16:21.933Z","date_formatted":{"ll":"Dec 2, 2025","L":"12/02/2025","MM-DD":"12-02"},"updated":"2025-12-02T14:16:21.933Z","content":"<h3 id=\"hmm\">HMM<a title=\"#hmm\" href=\"#hmm\"></a></h3>\n<h4 id=\"三个参数\">三个参数<a title=\"#三个参数\" href=\"#三个参数\"></a></h4>\n<p>我们这个HMM模型，含有三种参数，定义如下:<br>\n$$<br>\n\\lambda =（\\pi,A,B）<br>\n$$<br>\n注解:</p>\n<p>首先<br>\n$$<br>\n\\pi： 这里不是我们的圆周率那个符号，而是代表的是初始概率矩阵，具体看下面的讲解<br>\n$$<br>\n其次<br>\n$$<br>\nA：代表的是状态转移概率矩阵，具体看下面的讲解<br>\n$$<br>\n最后<br>\n$$<br>\nB：代表的是发射概率矩阵，具体看下面的讲解<br>\n$$</p>\n<p>现在引入数学符号，首先定义观测变量为符号:<br>\n$$<br>\no: o_{1},o_{2},o_{3},o_{4}…o_{t}…<br>\n$$<br>\n观测变量的值域，也就是观测变量的取值范围：<br>\n$$<br>\nV={v_{1},v_{2},…v_{M}}<br>\n$$<br>\n也就是观测变量我们有M个取值结果。</p>\n<p>同理我们可以得到状态变量为:<br>\n$$<br>\ni: i_{1},i_{2},i_{3}…i_{t}…<br>\n$$<br>\n状态变量的值域，也就是状态变量的取值范围：<br>\n$$<br>\nQ={q_{1},q_{2}…g_{N}}<br>\n$$<br>\n也就是说，我们的状态变量有N个不同的取值。</p>\n<p>我们定义A为状态转移概率矩阵，公式定义为:<br>\n$$<br>\nA=[a_{ij}]，其中a_{ij}=P(i_{t+1}=q_{j}|i_{t}=q_{i})<br>\n$$<br>\n注解：这里我们的状态转移概率矩阵很容易理解，就是说我们上面不是定义了状态变量为符号<br>\n$$<br>\ni<br>\n$$<br>\n，其中状态有N种取值范围。我们以词向标注为例，这里我们假设我们的N有四种方式，分别为[名词，动词，谓词，形容词]。那么A这个矩阵中的每个元素就是其中一个状态转移到另一个状态的概率，比如名词之后接动词（也就是名词转移为动词）的概率，比如动词之后接谓词（也就是动词转移为谓词）的概率，依次类推。</p>\n<p>我们定义B为发射矩阵<br>\n$$<br>\nB=[ b_{j}(k)], 其中b_{j}(k)=P(o_{t}=v_{k}|i_{t}=q_{j})<br>\n$$<br>\n注解：这里简单记住，发射矩阵就是上面状态发射到下面的概率，注意看箭头的方向。</p>\n<p>这个时候，我们再去看<br>\n$$<br>\n\\pi ：这个符号代表的就是 i_{1}={q_{1},q_{2}…q_{n}}时的状态概率{q_{1},q{2}…q_{n}}<br>\n$$</p>\n<h4 id=\"两个假设：\">两个假设：<a title=\"#两个假设：\" href=\"#两个假设：\"></a></h4>\n<ol>\n<li>\n<p>马尔科夫假设：当前时刻的状态变量只与t-1时刻有关，而和别的变量无关。<br>\n$$<br>\np(i_{t+1}|i_{t},i_{t-1}…i_{1},o_{t},o_{t-1}…o_{1})=p(i_{t+1}|i_{t})<br>\n$$</p>\n</li>\n<li>\n<p>齐次性假设，可以理解为时间平移不变</p>\n</li>\n</ol>\n<p>![image-20201221164438044](/Users/zida/Library/Application%20Support/typora-u](…/image-20201221164438044.png)</p>\n<ol start=\"3\">\n<li>观测独立假设：当前的观测变量只与当前时刻的状态变量有关，而和其他无关</li>\n</ol>\n<p>$$<br>\np(o_{t}|i_{t},i_{t-1},…i_{1},o_{t-1},…o_{1})=p(o_{t}|i_{t})<br>\n$$</p>\n<h3 id=\"三个需要解决的问题\">三个需要解决的问题<a title=\"#三个需要解决的问题\" href=\"#三个需要解决的问题\"></a></h3>\n<p>HMM 需要解决的问题。</p>\n<p>首先求值问题：已经知道三种参数的情况下，那么我一句话出现的概率多大：我爱中共产党</p>\n<p>简单讲就是已知<br>\n$$<br>\n\\lambda<br>\n$$<br>\n求<br>\n$$<br>\no_{1},o_{2}…o{n}<br>\n$$<br>\n这句话出现的概率有多大。</p>\n<p>我们常用的算法是前向后向算法。前向算法后向算法解决的问题是求在给定三个参数的情况下求观测序列出现的概率  注意一定是求得观测序列，也就是放在序列标注中，是求我们本身文字序列出现的概率。</p>\n<p>第二个问题，就是参数如何求？<br>\n$$<br>\n也就是如何求得：\\lambda<br>\n$$<br>\n我们使用EM算法求得这个参数</p>\n<p>EM算法是在估计HMM三个参数的办法。当然之前有谈到如果我们有观测序列和对应的隐藏序列，那么我们直接从数据中去统计就可以了。但是现实情况是我们很难获取标注序列，也就是隐藏序列。这个时候我们就需要使用到EM算法去预估。</p>\n<p>也就是，如果没有标注序列，我们使用EM算法，如果有了标注序列我们直接从语料中统计出来就可以了。</p>\n<p>第三个问题就是解码问题，也就是要找到一个状态序列，可以使得<br>\n$$<br>\nI=argmaxP(I|O)<br>\n$$<br>\n也就是解决当前这个句子最有可能的序列标注结果是什么样子的。</p>\n<p>HMM最可能的额隐藏状态序列求解使用维特比算法。</p>\n<p>使用一句话话可以很精辟的总结出来维特比的过程：</p>\n<p>在每一时刻，计算当前时刻落在每种隐状态的最大概率，并记录这个最大概率是从其哪一个时刻那个隐状态转移过来的，然后再从结尾达到最大概率的那个隐状态回溯，就有可能得到最优路径。</p>\n<p>维特比使用动态规划，解决寻找全局最优路径的问题。</p>\n<h3 id=\"crf\">CRF<a title=\"#crf\" href=\"#crf\"></a></h3>\n<h4 id=\"全局归一化避免偏置\">全局归一化避免偏置<a title=\"#全局归一化避免偏置\" href=\"#全局归一化避免偏置\"></a></h4>\n<p>对于CRF我们的目标函数是让正确的标注序列出现的概率在所有路径汇总是最大的。所以分母我们是针对的所有路径。而不是在每一个时刻去计算最优值。因为在某一个时刻计算的最优可能在整体路径上并不是最优。</p>\n<h4 id=\"分数并不是概率\">分数并不是概率<a title=\"#分数并不是概率\" href=\"#分数并不是概率\"></a></h4>\n<p>在bilstm-crf中，我们包括转移分数，发射分数，我们都是分数而不是概率。并且我们是做了log操作的，所以在计算某个路径的分数的时候我们并不是概率相乘而是分数相加。</p>\n<h4 id=\"损失函数\">损失函数<a title=\"#损失函数\" href=\"#损失函数\"></a></h4>\n<p>损失函数其实本质很简单，就是正确路径概率最大，拆分之后我们会对应两个部分一个是一元分值，就是在某个时刻成为某个实体标签的分数。一个是二元分值，就是标签之间的转移分数。</p>\n<h4 id=\"解码-维特比\">解码-维特比<a title=\"#解码-维特比\" href=\"#解码-维特比\"></a></h4>\n<p>在每一时刻，计算当前时刻落在每种隐状态的最大概率，并记录这个最大概率是从其哪一个时刻那个隐状态转移过来的，然后再从结尾达到最大概率的那个隐状态回溯，就有可能得到最优路径。</p>\n","link":"links/NLP_ability/深度学习自然语言处理/命名体识别/HMM_CRF","comments":true,"plink":"http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/HMM_CRF/","toc":[{"id":"hmm","title":"HMM","index":"1"},{"id":"三个需要解决的问题","title":"三个需要解决的问题","index":"2"},{"id":"crf","title":"CRF","index":"3"}],"reward":true}