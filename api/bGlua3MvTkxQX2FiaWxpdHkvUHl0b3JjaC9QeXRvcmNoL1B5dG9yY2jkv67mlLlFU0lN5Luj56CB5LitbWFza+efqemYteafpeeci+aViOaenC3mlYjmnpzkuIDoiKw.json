{"title":"","date":"2025-12-02T22:46:35.435Z","date_formatted":{"ll":"Dec 2, 2025","L":"12/02/2025","MM-DD":"12-02"},"updated":"2025-12-02T14:46:35.435Z","content":"<p>Pytorch修改ESIM代码中mask矩阵查看效果-效果一般<br>\n我对ESIM中的mask矩阵有所怀疑，于是自己改写了一个mask的矩阵，不过效果确实没有原始的好，很奇怪</p>\n<p><a href=\"https://github.com/DA-southampton/TextMatch/blob/master/ESIM/utils.py\" target=\"_blank\">https://github.com/DA-southampton/TextMatch/blob/master/ESIM/utils.py</a><br>\n就是这个链接中，我改了主要是以下两个函数的部分地方：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_mask</span>(<span class=\"params\">sequences_batch, sequences_lengths</span>):</span><br><span class=\"line\">    batch_size = sequences_batch.size()[<span class=\"number\">0</span>]</span><br><span class=\"line\">    max_length = torch.<span class=\"built_in\">max</span>(sequences_lengths)</span><br><span class=\"line\">    mask = torch.ones(batch_size, max_length, dtype=torch.<span class=\"built_in\">float</span>)</span><br><span class=\"line\">    mask[sequences_batch[:, :max_length] == <span class=\"number\">0</span>] = -<span class=\"number\">10000.0</span> <span class=\"comment\">## 这里修改为-10000，印象中抱抱脸初始版本是这么实现的</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> mask\t</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">masked_softmax</span>(<span class=\"params\">tensor, mask</span>):</span><br><span class=\"line\">    tensor_shape = tensor.size()</span><br><span class=\"line\">    reshaped_tensor = tensor.view(-<span class=\"number\">1</span>, tensor_shape[-<span class=\"number\">1</span>])</span><br><span class=\"line\">    <span class=\"comment\"># Reshape the mask so it matches the size of the input tensor.</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> mask.dim() &lt; tensor.dim():</span><br><span class=\"line\">        mask = mask.unsqueeze(<span class=\"number\">1</span>)</span><br><span class=\"line\">    mask = mask.expand_as(tensor).contiguous().<span class=\"built_in\">float</span>()</span><br><span class=\"line\">    reshaped_mask = mask.view(-<span class=\"number\">1</span>, mask.size()[-<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    result = nn.functional.softmax(reshaped_tensor+reshaped_mask, dim=-<span class=\"number\">1</span>) <span class=\"comment\">## 这里变为加</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> result.view(*tensor_shape)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>改完之后效果不咋样，真的很奇怪</p>\n","link":"links/NLP_ability/Pytorch/Pytorch/Pytorch修改ESIM代码中mask矩阵查看效果-效果一般","comments":true,"plink":"http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch/Pytorch修改ESIM代码中mask矩阵查看效果-效果一般/","reward":true}