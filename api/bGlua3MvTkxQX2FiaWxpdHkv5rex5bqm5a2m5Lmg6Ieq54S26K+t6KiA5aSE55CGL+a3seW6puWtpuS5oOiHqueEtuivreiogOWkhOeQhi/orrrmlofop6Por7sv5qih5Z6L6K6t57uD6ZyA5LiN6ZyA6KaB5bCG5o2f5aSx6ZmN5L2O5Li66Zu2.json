{"title":"","date":"2025-12-02T22:37:33.083Z","date_formatted":{"ll":"Dec 2, 2025","L":"12/02/2025","MM-DD":"12-02"},"updated":"2025-12-02T14:37:33.083Z","content":"<p>本文是对苏神文章的解读，主要是关于公式推导中省略的部分细节记录了自己的理解，希望能帮助大家更好的理解。</p>\n<p>模型训练的时候，我们会把数据分为训练数据和开发数据。</p>\n<p>Loss变化一般是这样的：训练集损失在不停的降低，开发集先降低随后上升。</p>\n<p>我们一般选择两条线的交叉点（其实也没有交叉），也就是开发数据集开始上升的那个点作为我们的最终模型的选择，这样既可以得到最好的结果，也可以避免过拟合。</p>\n<p>这个论文思路是这样的，当损失函数降低的一定程度（足够小）的时候，改变损失函数为:<br>\n$$<br>\n\\widetilde{J_{\\theta}} =|J_{\\theta}-b|+b\\tag{1}<br>\n$$</p>\n<p>公式 $(1)$ 中 $J_{\\theta}$  为原始的损失函数， $\\widetilde{J_{\\theta}}$ 改变之后的损失函数。</p>\n<p>观察这个公式，其实可以这样去描述：</p>\n<ol>\n<li>\n<p>当 $J_{\\theta} \\geq b$ 时，损失函数就是$J_{\\theta}$；</p>\n</li>\n<li>\n<p>当$J_{\\theta} &lt; b$ 的时候，损失函数就是$\\widetilde{J_{\\theta}}=2b - J_{\\theta}$。</p>\n</li>\n</ol>\n<p>这个时候，我们想一下梯度下降算法公式，如下:<br>\n$$<br>\n\\theta_{n}=\\theta_{n-1}- \\alpha\\nabla J(\\theta_{n-1})\\tag{2}<br>\n$$</p>\n<p>所以，当损失函数为 $\\widetilde{J_{\\theta}}$ 的时候，符号就会发生变化，这个时候我们就使用就不是梯度下降而是梯度上升算法。也就是说，以$b$ 为临界点，在交替的进行梯度上升和梯度下降算法。</p>\n<p>论文发现，在某些任务上，使用这个方法，开发集上的损失函数会发生二次下降。</p>\n<p>再次说一下，关于这一点，苏剑林给出来相关的数学推导（参考链接放在文章末尾）。不过有个关于泰勒公式的展开跳过了，我简单做了一个补充，帮助自己和大家理解。</p>\n<p>首先如果交替做梯度上升和梯度下降算法，参数更新公式如下所示:<br>\n$$<br>\n\\theta_{n}=\\theta_{n-1}- \\alpha\\nabla J(\\theta_{n-1})<br>\n$$</p>\n<p>$$<br>\n\\theta_{n+1}=\\theta_{n}+ \\alpha\\nabla J(\\theta_{n}) \\tag{3}<br>\n$$</p>\n<p>对此公式上下消参 中，我们可以得到：<br>\n$$<br>\n\\theta_{n+1}= \\theta_{n-1}- \\alpha\\nabla J(\\theta_{n-1})+ \\alpha\\nabla J( \\theta_{n-1}- \\alpha\\nabla J(\\theta_{n-1}))\\tag{4}<br>\n$$<br>\n对于公式$(4)$ ，重点是对 <strong>$ J(\\theta_{n-1}- \\alpha\\nabla J(\\theta_{n-1}))$</strong> 这个损失函数进行一个剖析化简，这里用到了泰勒公式的展开。</p>\n<p>先回忆一下泰勒公式，这里直接给出一个一阶泰勒公式的展开:<br>\n$$<br>\nJ(\\omega) \\approx   J(\\omega_{0}) + (\\omega - \\omega_{0})*J^{'}(\\omega_{0}) + \\epsilon  \\qquad  \\omega_{0} 和 \\omega 足够接近\\tag{5}<br>\n$$<br>\n注意，这个时候，我们仔细观察公式  <strong>$ J(\\theta_{n-1}- \\alpha\\nabla J(\\theta_{n-1}))$</strong>  和 公式$(5)$。</p>\n<p>首先，我们知道的是，$\\alpha\\nabla J(\\theta_{n-1}))$ 是每次参数更新时候的增量，在损失函数足够小的时候，我们每次参数更新的增量可以认定是一个极小值。</p>\n<p>换句话说，$\\theta_{n-1}- \\alpha\\nabla J(\\theta_{n-1})$可以对应到我们公式(5) 中的$\\omega_{0}$，$\\theta_{n-1}$ 对应的就是公式(5) 中的 $\\omega$</p>\n<p>也就是说，<br>\n$$<br>\nJ( \\theta_{n-1}) \\approx  J( \\theta_{n-1}- \\alpha\\nabla J(\\theta_{n-1})) +\\alpha\\nabla J(\\theta_{n-1})*\\nabla J(\\theta_{n-1})  \\tag{6}<br>\n$$<br>\n这里需要注意的，公式最后面一个$\\nabla J(\\theta_{n-1})$ 的由来。按道理，这里应该是对$J^{'}(\\omega_{0})$进行求导 。但是这里因为$\\omega 和 \\omega_{0}$ 非常的相近，我们直接使用对$J(\\omega)$的求导结果就可以，这一点是个比较重要的细节点。</p>\n<p>基于此，我们可以继续往下推导：</p>\n<p>$$<br>\n\\theta_{n+1}= \\theta_{n-1}- \\alpha\\nabla J(\\theta_{n-1})+ \\alpha\\nabla J( \\theta_{n-1}- \\alpha\\nabla J(\\theta_{n-1}))<br>\n$$</p>\n<p>$$<br>\n\\approx \\theta_{n-1}- \\alpha\\nabla J(\\theta_{n-1})+ \\alpha\\nabla (J (\\theta_{n-1})- \\alpha\\nabla J(\\theta_{n-1})*\\nabla J(\\theta_{n-1}))<br>\n$$</p>\n<p>$$<br>\n= \\theta_{n-1}- \\alpha\\nabla J(\\theta_{n-1})+ \\alpha\\nabla J (\\theta_{n-1})- \\alpha^{2}\\nabla (\\nabla J(\\theta_{n-1})*\\nabla J(\\theta_{n-1}))<br>\n$$</p>\n<p>$$<br>\n= \\theta_{n-1}- \\alpha^{2}\\nabla ||\\nabla J(\\theta_{n-1})||^{2}  \\tag{7}<br>\n$$</p>\n<p>这里，我还想提一点就是 $||\\nabla J(\\theta_{n-1})||^{2}$ ，它是两个求微分函数的乘积，所以结果是一个带参数的函数，也就是求得一个微分之后，做一个平方，得到的函数，这个时候在参数更新的时候，我们带入相应的值就可以了。</p>\n<p>我们针对这个公式(7)，会发现一个很奇怪的现象，就是参数更新的模式没有发生变化，都是进行了梯度下降（注意开头我们单从损失函数看是认为梯度下降和梯度上升是交替进行的，两个理解其实都没有问题）。</p>\n<p>只是，当前步骤的参数更新不再是取决于上一个步骤，而是取决于上上一个步骤的参数。</p>\n<p>这一点，我是这么理解的。使用普通的损失函数，相当于此时我们站在上一个步骤往山下看。当损失函数非常小的时候，极有可能会陷入局部最小值，并不是全局最优点。此时寻找出来的更新的方向，还是局限于局部最优点。而使用新的损失函数，我们通过公式，最直观的感受就是，是站在了上上一个步骤，是脱离了当前的视线(虽然只是差了一个步骤)，相当于视野变大了，有更大的可能跳出当前的局部最优点，从而寻找到全局最优点。</p>\n<p>我的理解就是这样的，当然苏神给出了另一个解释。大家可以去看一下。我这个文章主要是对他的公式推导中的跳过的泰勒公式的展开做了一个比较详细的阐述，记录下来，方便自己和大家理解。</p>\n","link":"links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/论文解读/模型训练需不需要将损失降低为零","comments":true,"plink":"http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/论文解读/模型训练需不需要将损失降低为零/","reward":true}