{"title":"","date":"2025-12-02T22:46:35.603Z","date_formatted":{"ll":"Dec 2, 2025","L":"12/02/2025","MM-DD":"12-02"},"updated":"2025-12-02T14:46:35.603Z","content":"<h1 id=\"quickstart\">Quickstart<a title=\"#quickstart\" href=\"#quickstart\"></a></h1>\n<h3 id=\"step-1:-preprocess-the-data\">Step 1: Preprocess the data<a title=\"#step-1:-preprocess-the-data\" href=\"#step-1:-preprocess-the-data\"></a></h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">onmt_preprocess -train_src data/src-train.txt -train_tgt data/tgt-train.txt -valid_src data/src-val.txt -valid_tgt data/tgt-val.txt -save_data data/demo</span><br></pre></td></tr></table></figure>\n<p>We will be working with some example data in <code>data/</code> folder.</p>\n<p>The data consists of parallel source (<code>src</code>) and target (<code>tgt</code>) data containing one sentence per line with tokens separated by a space:</p>\n<ul>\n<li><code>src-train.txt</code></li>\n<li><code>tgt-train.txt</code></li>\n<li><code>src-val.txt</code></li>\n<li><code>tgt-val.txt</code></li>\n</ul>\n<p>Validation files are required and used to evaluate the convergence of the training. It usually contains no more than 5000 sentences.</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ head -n 3 data/src-train.txt</span><br><span class=\"line\">It is not acceptable that , with the help of the national bureaucracies , Parliament &amp;apos;s legislative prerogative should be made null and void by means of implementing provisions whose content , purpose and extent are not laid down in advance .</span><br><span class=\"line\">Federal Master Trainer and Senior Instructor of the Italian Federation of Aerobic Fitness , Group Fitness , Postural Gym , Stretching and Pilates; from 2004 , he has been collaborating with Antiche Terme as personal Trainer and Instructor of Stretching , Pilates and Postural Gym .</span><br><span class=\"line\">&amp;quot; Two soldiers came up to me and told me that if I refuse to sleep with them , they will kill me . They beat me and ripped my clothes .</span><br></pre></td></tr></table></figure>\n<h3 id=\"step-2:-train-the-model\">Step 2: Train the model<a title=\"#step-2:-train-the-model\" href=\"#step-2:-train-the-model\"></a></h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">onmt_train -data data/demo -save_model demo-model</span><br></pre></td></tr></table></figure>\n<p>The main train command is quite simple. Minimally it takes a data file<br>\nand a save file.  This will run the default model, which consists of a<br>\n2-layer LSTM with 500 hidden units on both the encoder/decoder.<br>\nIf you want to train on GPU, you need to set, as an example:<br>\nCUDA_VISIBLE_DEVICES=1,3<br>\n<code>-world_size 2 -gpu_ranks 0 1</code> to use (say) GPU 1 and 3 on this node only.<br>\nTo know more about distributed training on single or multi nodes, read the FAQ section.</p>\n<h3 id=\"step-3:-translate\">Step 3: Translate<a title=\"#step-3:-translate\" href=\"#step-3:-translate\"></a></h3>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">onmt_translate -model demo-model_XYZ.pt -src data/src-test.txt -output pred.txt -replace_unk -verbose</span><br></pre></td></tr></table></figure>\n<p>Now you have a model which you can use to predict on new data. We do this by running beam search. This will output predictions into <code>pred.txt</code>.</p>\n<p>Note:</p>\n<p>The predictions are going to be quite terrible, as the demo dataset is small. Try running on some larger datasets! For example you can download millions of parallel sentences for <a href=\"http://www.statmt.org/wmt16/translation-task.html\" target=\"_blank\">translation</a> or <a href=\"https://github.com/harvardnlp/sent-summary\" target=\"_blank\">summarization</a>.</p>\n","link":"links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/quickstart","comments":true,"plink":"http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/quickstart/","toc":[{"id":"quickstart","title":"Quickstart","index":"1","children":[{"id":"step-1:-preprocess-the-data","title":"Step 1: Preprocess the data","index":"1.1"},{"id":"step-2:-train-the-model","title":"Step 2: Train the model","index":"1.2"},{"id":"step-3:-translate","title":"Step 3: Translate","index":"1.3"}]}],"reward":true}