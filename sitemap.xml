<?xml version="1.0" encoding="UTF-8"?><urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"><url><loc>http://www.ephesus.top/2025/win10_4.2_BSD/</loc><lastmod>2025-12-02T14:46:33.731Z</lastmod></url><url><loc>http://www.ephesus.top/2024/in_decline/</loc><lastmod>2025-12-02T14:46:33.730Z</lastmod></url><url><loc>http://www.ephesus.top/2024/lunch_in_the_library/</loc><lastmod>2025-12-02T14:46:33.730Z</lastmod></url><url><loc>http://www.ephesus.top/2024/dejavu/</loc><lastmod>2025-12-02T14:46:33.730Z</lastmod></url><url><loc>http://www.ephesus.top/2024/dwarfs_best_friend/</loc><lastmod>2025-12-02T14:46:33.730Z</lastmod></url><url><loc>http://www.ephesus.top/2024/man_behind_curtain/</loc><lastmod>2025-12-02T14:46:33.731Z</lastmod></url><url><loc>http://www.ephesus.top/2024/magma/</loc><lastmod>2025-12-02T14:46:33.731Z</lastmod></url><url><loc>http://www.ephesus.top/2024/practice_and_atmospheric/</loc><lastmod>2025-12-02T14:46:33.731Z</lastmod></url><url><loc>http://www.ephesus.top/2024/foocubus/</loc><lastmod>2025-12-02T14:46:33.730Z</lastmod></url><url><loc>http://www.ephesus.top/2024/demogorgon_patch_4/</loc><lastmod>2025-12-02T14:46:33.730Z</lastmod></url><url><loc>http://www.ephesus.top/2024/demogorgon_patch_3/</loc><lastmod>2025-12-02T14:46:33.730Z</lastmod></url><url><loc>http://www.ephesus.top/2024/demogorgon_patch_2/</loc><lastmod>2025-12-02T14:46:33.730Z</lastmod></url><url><loc>http://www.ephesus.top/2024/BoMENet-arc/</loc><lastmod>2025-12-02T14:46:33.729Z</lastmod></url><url><loc>http://www.ephesus.top/2024/Avanor/</loc><lastmod>2025-12-02T14:46:33.729Z</lastmod></url><url><loc>http://www.ephesus.top/2023/demogorgon_patch_1/</loc><lastmod>2025-12-02T14:46:33.730Z</lastmod></url><url><loc>http://www.ephesus.top/2023/ChatGPT-receipt/</loc><lastmod>2025-12-02T14:46:33.730Z</lastmod></url><url><loc>http://www.ephesus.top/2022/another_yasd/</loc><lastmod>2025-12-02T14:46:33.730Z</lastmod></url><url><loc>http://www.ephesus.top/2022/just_readme/</loc><lastmod>2025-12-02T14:46:33.730Z</lastmod></url><url><loc>http://www.ephesus.top/about/</loc><lastmod>2025-12-02T14:46:33.731Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:33.733Z</lastmod></url><url><loc>http://www.ephesus.top/links/</loc><lastmod>2025-12-02T14:46:35.628Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/</loc><lastmod>2025-12-02T14:46:34.572Z</lastmod></url><url><loc>http://www.ephesus.top/roguelike/</loc><lastmod>2025-12-02T14:46:35.629Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/</loc><lastmod>2025-12-02T14:46:35.435Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Cheat/</loc><lastmod>2025-12-02T14:46:33.797Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/</loc><lastmod>2025-12-02T14:46:33.919Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/IMG Dos/</loc><lastmod>2025-12-02T14:46:33.948Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Other Platform/</loc><lastmod>2025-12-02T14:46:34.557Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Picture/</loc><lastmod>2025-12-02T14:46:34.564Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Scenario/</loc><lastmod>2025-12-02T14:46:34.569Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Sound/</loc><lastmod>2025-12-02T14:46:34.570Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Update/</loc><lastmod>2025-12-02T14:46:34.571Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Win/</loc><lastmod>2025-12-02T14:46:34.571Z</lastmod></url><url><loc>http://www.ephesus.top/files/Avanor/Avanor/</loc><lastmod>2025-12-02T14:46:33.745Z</lastmod></url><url><loc>http://www.ephesus.top/files/tomenet/BoMENet-arc/</loc><lastmod>2025-12-02T14:46:35.127Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch中mask是如何实现的代码版本1-阅读文本相似度模型/</loc><lastmod>2025-12-02T14:46:35.435Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch修改ESIM代码中mask矩阵查看效果-效果一般/</loc><lastmod>2025-12-02T14:46:35.435Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/README/</loc><lastmod>2025-12-02T14:46:35.435Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/pytorch处理文本数据代码版本1-处理文本相似度数据/</loc><lastmod>2025-12-02T14:46:35.435Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/pytorch处理文本数据代码版本2-处理文本相似度数据/</loc><lastmod>2025-12-02T14:46:35.435Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/pytorch对text数据的预处理-综述/</loc><lastmod>2025-12-02T14:46:35.435Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/FM/</loc><lastmod>2025-12-02T14:46:35.435Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/deepfm/</loc><lastmod>2025-12-02T14:46:35.437Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/推荐资源更新/</loc><lastmod>2025-12-02T14:46:35.448Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/搜索/倒排索引基本概念/</loc><lastmod>2025-12-02T14:46:35.448Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/搜索/搜索资源总结-持续更新/</loc><lastmod>2025-12-02T14:46:35.448Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_474_01/</loc><lastmod>2025-12-02T14:46:33.813Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_474_03/</loc><lastmod>2025-12-02T14:46:33.828Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_474_04/</loc><lastmod>2025-12-02T14:46:33.843Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_474_05/</loc><lastmod>2025-12-02T14:46:33.857Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_474_05Fr/</loc><lastmod>2025-12-02T14:46:33.871Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_475_01/</loc><lastmod>2025-12-02T14:46:33.885Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_475_01Rus/</loc><lastmod>2025-12-02T14:46:33.901Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/IMG Dos/IMG_474_01/</loc><lastmod>2025-12-02T14:46:33.940Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/IMG Dos/IMG_474_04/</loc><lastmod>2025-12-02T14:46:33.943Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/IMG Dos/IMG_475_01/</loc><lastmod>2025-12-02T14:46:33.946Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/IMG Dos/IMG_475_02G/</loc><lastmod>2025-12-02T14:46:33.948Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Scenario/JustForWin/</loc><lastmod>2025-12-02T14:46:34.566Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Update/PowerMac Fix/</loc><lastmod>2025-12-02T14:46:34.571Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_475_02G/</loc><lastmod>2025-12-02T14:46:33.919Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.007Z</lastmod></url><url><loc>http://www.ephesus.top/files/rl/emeraldwoods/web/</loc><lastmod>2025-12-02T14:46:35.007Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.012Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.012Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.012Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch/Pytorch中mask是如何实现的代码版本1-阅读文本相似度模型/</loc><lastmod>2025-12-02T14:46:35.435Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch/Pytorch修改ESIM代码中mask矩阵查看效果-效果一般/</loc><lastmod>2025-12-02T14:46:35.435Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch/README/</loc><lastmod>2025-12-02T14:46:35.435Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch/pytorch处理文本数据代码版本1-处理文本相似度数据/</loc><lastmod>2025-12-02T14:46:35.435Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch/pytorch处理文本数据代码版本2-处理文本相似度数据/</loc><lastmod>2025-12-02T14:46:35.435Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch/pytorch对text数据的预处理-综述/</loc><lastmod>2025-12-02T14:46:35.435Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/WDL/WDL在贝壳中的应用实践总结/</loc><lastmod>2025-12-02T14:46:35.437Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/WDL/WDl/</loc><lastmod>2025-12-02T14:46:35.437Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/推荐/FM/</loc><lastmod>2025-12-02T14:46:35.442Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/推荐/deepfm/</loc><lastmod>2025-12-02T14:46:35.443Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/推荐/推荐资源更新/</loc><lastmod>2025-12-02T14:46:35.448Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/搜索/搜索/倒排索引基本概念/</loc><lastmod>2025-12-02T14:46:35.448Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/搜索/搜索/搜索资源总结-持续更新/</loc><lastmod>2025-12-02T14:46:35.448Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/ALBERT-更小更少但并不快/</loc><lastmod>2025-12-02T14:46:35.449Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/Bert各种后续预训练模型-预训练模型的改进/</loc><lastmod>2025-12-02T14:46:35.450Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/Bert如何融入知识一-百度和清华ERINE/</loc><lastmod>2025-12-02T14:46:35.450Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/Bert如何融入知识二-Bert融合知识图谱/</loc><lastmod>2025-12-02T14:46:35.450Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/Bert的可视化-Bert每一层都学到了什么/</loc><lastmod>2025-12-02T14:46:35.450Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/Bert资源总结/</loc><lastmod>2025-12-02T14:46:35.450Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/FastBert/</loc><lastmod>2025-12-02T14:46:35.450Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/Pytorch代码分析-如何让Bert在finetune小数据集时更“稳”一点/</loc><lastmod>2025-12-02T14:46:35.452Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/RoBERTa/</loc><lastmod>2025-12-02T14:46:35.452Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/UniLM/</loc><lastmod>2025-12-02T14:46:35.454Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/XLNET/</loc><lastmod>2025-12-02T14:46:35.454Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/tBERT-BERT融合主题模型/</loc><lastmod>2025-12-02T14:46:35.459Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/为什么Bert做不好无监督语义匹配/</loc><lastmod>2025-12-02T14:46:35.461Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/如何在脱敏数据中使用BERT等预训练模型/</loc><lastmod>2025-12-02T14:46:35.461Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/解决老大难问题-如何一行代码带你随心所欲重新初始化bert的某些参数附Pytorch代码/</loc><lastmod>2025-12-02T14:46:35.461Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/3分钟从零解读Transformer的Encoder/</loc><lastmod>2025-12-02T14:46:35.461Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/BN踩坑记--谈一下Batch Normalization的优缺点和适用场景/</loc><lastmod>2025-12-02T14:46:35.461Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/NLP任务中-layer-norm比BatchNorm好在哪里/</loc><lastmod>2025-12-02T14:46:35.461Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/Transformer的并行化/</loc><lastmod>2025-12-02T14:46:35.461Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/Transformer面试题全部答案解析合辑/</loc><lastmod>2025-12-02T14:46:35.461Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/VIT-如何将Transformer更好的应用到CV领域/</loc><lastmod>2025-12-02T14:46:35.461Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/transformer-bert资源总结/</loc><lastmod>2025-12-02T14:46:35.467Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/transformer资源总结/</loc><lastmod>2025-12-02T14:46:35.467Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/原版Transformer的位置编码究竟有没有包含相对位置信息/</loc><lastmod>2025-12-02T14:46:35.467Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/史上最全Transformer面试题/</loc><lastmod>2025-12-02T14:46:35.467Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/答案解析—史上最全Transformer面试题：灵魂20问帮你彻底搞定Transformer/</loc><lastmod>2025-12-02T14:46:35.467Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/谈一下相对位置编码/</loc><lastmod>2025-12-02T14:46:35.467Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/谈一谈Decoder模块/</loc><lastmod>2025-12-02T14:46:35.468Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/关键词提取/README/</loc><lastmod>2025-12-02T14:46:35.468Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/关键词提取/关键词提取方法综述/</loc><lastmod>2025-12-02T14:46:35.468Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/关键词提取/关键词提取资源总结/</loc><lastmod>2025-12-02T14:46:35.468Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/关键词提取/实体库构建：大规模离线新词实体挖掘/</loc><lastmod>2025-12-02T14:46:35.468Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/其他/RNN的梯度消失有什么与众不同的地方/</loc><lastmod>2025-12-02T14:46:35.469Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/其他/20201210一周技术问题答疑汇总/</loc><lastmod>2025-12-02T14:46:35.469Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/答案合辑/</loc><lastmod>2025-12-02T14:46:35.467Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/句向量/README/</loc><lastmod>2025-12-02T14:46:35.469Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/FLAT-Transformer/</loc><lastmod>2025-12-02T14:46:35.471Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/句向量/句向量模型综述/</loc><lastmod>2025-12-02T14:46:35.471Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/HMM_CRF/</loc><lastmod>2025-12-02T14:46:35.474Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/README/</loc><lastmod>2025-12-02T14:46:35.474Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/TNER-复旦为什么TRM在NER上效果差/</loc><lastmod>2025-12-02T14:46:35.478Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/autoner/</loc><lastmod>2025-12-02T14:46:35.478Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/命名体识别资源梳理（代码+博客讲解）/</loc><lastmod>2025-12-02T14:46:35.481Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/词典匹配+模型预测-实体识别两大法宝/</loc><lastmod>2025-12-02T14:46:35.482Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/工业级命名体识别的做法/</loc><lastmod>2025-12-02T14:46:35.482Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/复盘多模态需要解决的6个问题/</loc><lastmod>2025-12-02T14:46:35.482Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/多模态中各种Fusion方式汇总/</loc><lastmod>2025-12-02T14:46:35.482Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/多模态之ViLBERT：双流网络，各自为王/</loc><lastmod>2025-12-02T14:46:35.482Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/多模态资源汇总/</loc><lastmod>2025-12-02T14:46:35.482Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/如何将多模态数据融入到BERT架构中-多模态BERT的两类预训练任务/</loc><lastmod>2025-12-02T14:46:35.482Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/层次体系的构建-多模态解析/</loc><lastmod>2025-12-02T14:46:35.482Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/层次分类体系的必要性-多模态讲解系列/</loc><lastmod>2025-12-02T14:46:35.482Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/文本和图像特征表示模块详解-多模态讲解系列/</loc><lastmod>2025-12-02T14:46:35.482Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/对比学习/Moco1论文解析/</loc><lastmod>2025-12-02T14:46:35.482Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/ACL2020-多任务负监督方式增加CLS表达差异性/</loc><lastmod>2025-12-02T14:46:35.482Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/CNN文本分类解读/</loc><lastmod>2025-12-02T14:46:35.482Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/LCM-缓解标签不独立以及标注错误的问题/</loc><lastmod>2025-12-02T14:46:35.485Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/README/</loc><lastmod>2025-12-02T14:46:35.488Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/UDA/</loc><lastmod>2025-12-02T14:46:35.491Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/关键词信息如何融入到文本分类任务中/</loc><lastmod>2025-12-02T14:46:35.498Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/半监督入门思想之伪标签/</loc><lastmod>2025-12-02T14:46:35.498Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/在文本分类上微调Bert/</loc><lastmod>2025-12-02T14:46:35.498Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/只使用标签名称就可以文本分类/</loc><lastmod>2025-12-02T14:46:35.498Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/文本分类资源总结/</loc><lastmod>2025-12-02T14:46:35.500Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/DSSM论文-公司实战文章/</loc><lastmod>2025-12-02T14:46:35.501Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/ESIM/</loc><lastmod>2025-12-02T14:46:35.501Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/SIMCSE论文解析/</loc><lastmod>2025-12-02T14:46:35.505Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/bert白化简单的梳理/</loc><lastmod>2025-12-02T14:46:35.505Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/五千字全面梳理文本相似度和文本匹配模型/</loc><lastmod>2025-12-02T14:46:35.506Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/阿里RE2-将残差连接和文本匹配模型融合/</loc><lastmod>2025-12-02T14:46:35.506Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/聊一下孪生网络和DSSM的混淆点以及向量召回的一个细节/</loc><lastmod>2025-12-02T14:46:35.506Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本纠错/文本纠错资源总结/</loc><lastmod>2025-12-02T14:46:35.511Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/README/</loc><lastmod>2025-12-02T14:46:35.525Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/bpe-subword论文的我的阅读总结/</loc><lastmod>2025-12-02T14:46:35.525Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/Bert蒸馏到简单网络lstm/</loc><lastmod>2025-12-02T14:46:35.525Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/BERT知识蒸馏代码解析-如何写好损失函数/</loc><lastmod>2025-12-02T14:46:35.525Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/PKD-Bert基于多层的知识蒸馏方式/</loc><lastmod>2025-12-02T14:46:35.529Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/Theseus-模块压缩交替训练/</loc><lastmod>2025-12-02T14:46:35.529Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/bert2textcnn模型蒸馏/</loc><lastmod>2025-12-02T14:46:35.529Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/tinybert-全方位蒸馏/</loc><lastmod>2025-12-02T14:46:35.540Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/什么是知识蒸馏/</loc><lastmod>2025-12-02T14:46:35.544Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/知识蒸馏综述万字长文/</loc><lastmod>2025-12-02T14:46:35.544Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/CBOW和skip-gram相较而言，彼此相对适合哪些场景/</loc><lastmod>2025-12-02T14:46:35.627Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/Fasttext解读1/</loc><lastmod>2025-12-02T14:46:35.627Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/Fasttext解读2/</loc><lastmod>2025-12-02T14:46:35.627Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/README/</loc><lastmod>2025-12-02T14:46:35.627Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/Word2vec为什么需要二次采样？/</loc><lastmod>2025-12-02T14:46:35.627Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/Word2vec模型究竟是如何获得词向量的/</loc><lastmod>2025-12-02T14:46:35.627Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/Word2vec的负采样/</loc><lastmod>2025-12-02T14:46:35.627Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/Word2vec训练参数的选定/</loc><lastmod>2025-12-02T14:46:35.627Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/word2vec两种优化方式的联系和区别/</loc><lastmod>2025-12-02T14:46:35.628Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/史上最全词向量面试题梳理/</loc><lastmod>2025-12-02T14:46:35.628Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/聊一下Glove/</loc><lastmod>2025-12-02T14:46:35.628Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/聊一下Word2vec-模型篇/</loc><lastmod>2025-12-02T14:46:35.628Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/聊一下Word2vec-细节篇/</loc><lastmod>2025-12-02T14:46:35.628Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/聊一下Word2vec-训练优化篇/</loc><lastmod>2025-12-02T14:46:35.628Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/词向量/</loc><lastmod>2025-12-02T14:46:35.628Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/词向量资源总结/</loc><lastmod>2025-12-02T14:46:35.628Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/论文解读/模型训练需不需要将损失降低为零/</loc><lastmod>2025-12-02T14:46:35.627Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.003Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.004Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.004Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.004Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.004Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.004Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.004Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.004Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.004Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.005Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.005Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.005Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.007Z</lastmod></url><url><loc>http://www.ephesus.top/files/rl/omega/JSOmega/JSomega/</loc><lastmod>2025-12-02T14:46:35.069Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/推荐/WDL/WDL在贝壳中的应用实践总结/</loc><lastmod>2025-12-02T14:46:35.443Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/推荐/WDL/WDl/</loc><lastmod>2025-12-02T14:46:35.443Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/关键词提取/中文分词/基于词典的正向最大匹配和逆向最大匹配中文分词/</loc><lastmod>2025-12-02T14:46:35.468Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/CHANGELOG/</loc><lastmod>2025-12-02T14:46:35.511Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/CONTRIBUTING/</loc><lastmod>2025-12-02T14:46:35.512Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/LICENSE/</loc><lastmod>2025-12-02T14:46:35.512Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/README/</loc><lastmod>2025-12-02T14:46:35.512Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/README_old/</loc><lastmod>2025-12-02T14:46:35.512Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.515Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/ALBERT-更小更少但并不快/</loc><lastmod>2025-12-02T14:46:35.544Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/Bert各种后续预训练模型-预训练模型的改进/</loc><lastmod>2025-12-02T14:46:35.546Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/Bert如何融入知识一-百度和清华ERINE/</loc><lastmod>2025-12-02T14:46:35.546Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/Bert如何融入知识二-Bert融合知识图谱/</loc><lastmod>2025-12-02T14:46:35.546Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/Bert的可视化-Bert每一层都学到了什么/</loc><lastmod>2025-12-02T14:46:35.546Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/Bert资源总结/</loc><lastmod>2025-12-02T14:46:35.546Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/FastBert/</loc><lastmod>2025-12-02T14:46:35.546Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/Pytorch代码分析-如何让Bert在finetune小数据集时更“稳”一点/</loc><lastmod>2025-12-02T14:46:35.548Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/RoBERTa/</loc><lastmod>2025-12-02T14:46:35.548Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/UniLM/</loc><lastmod>2025-12-02T14:46:35.550Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/XLNET/</loc><lastmod>2025-12-02T14:46:35.550Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/tBERT-BERT融合主题模型/</loc><lastmod>2025-12-02T14:46:35.555Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/为什么Bert做不好无监督语义匹配/</loc><lastmod>2025-12-02T14:46:35.556Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/如何在脱敏数据中使用BERT等预训练模型/</loc><lastmod>2025-12-02T14:46:35.556Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/解决老大难问题-如何一行代码带你随心所欲重新初始化bert的某些参数附Pytorch代码/</loc><lastmod>2025-12-02T14:46:35.556Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/3分钟从零解读Transformer的Encoder/</loc><lastmod>2025-12-02T14:46:35.556Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/BN踩坑记--谈一下Batch Normalization的优缺点和适用场景/</loc><lastmod>2025-12-02T14:46:35.557Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/NLP任务中-layer-norm比BatchNorm好在哪里/</loc><lastmod>2025-12-02T14:46:35.557Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/Transformer的并行化/</loc><lastmod>2025-12-02T14:46:35.557Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/Transformer面试题全部答案解析合辑/</loc><lastmod>2025-12-02T14:46:35.557Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/VIT-如何将Transformer更好的应用到CV领域/</loc><lastmod>2025-12-02T14:46:35.557Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/transformer-bert资源总结/</loc><lastmod>2025-12-02T14:46:35.563Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/transformer资源总结/</loc><lastmod>2025-12-02T14:46:35.563Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/原版Transformer的位置编码究竟有没有包含相对位置信息/</loc><lastmod>2025-12-02T14:46:35.563Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/史上最全Transformer面试题/</loc><lastmod>2025-12-02T14:46:35.563Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/答案合辑/</loc><lastmod>2025-12-02T14:46:35.563Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/答案解析—史上最全Transformer面试题：灵魂20问帮你彻底搞定Transformer/</loc><lastmod>2025-12-02T14:46:35.563Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/谈一谈Decoder模块/</loc><lastmod>2025-12-02T14:46:35.563Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/谈一下相对位置编码/</loc><lastmod>2025-12-02T14:46:35.563Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/关键词提取/README/</loc><lastmod>2025-12-02T14:46:35.563Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/关键词提取/关键词提取方法综述/</loc><lastmod>2025-12-02T14:46:35.564Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/关键词提取/关键词提取资源总结/</loc><lastmod>2025-12-02T14:46:35.564Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/关键词提取/实体库构建：大规模离线新词实体挖掘/</loc><lastmod>2025-12-02T14:46:35.564Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/其他/20201210一周技术问题答疑汇总/</loc><lastmod>2025-12-02T14:46:35.564Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/其他/RNN的梯度消失有什么与众不同的地方/</loc><lastmod>2025-12-02T14:46:35.564Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/句向量/README/</loc><lastmod>2025-12-02T14:46:35.564Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/句向量/句向量模型综述/</loc><lastmod>2025-12-02T14:46:35.565Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/FLAT-Transformer/</loc><lastmod>2025-12-02T14:46:35.565Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/README/</loc><lastmod>2025-12-02T14:46:35.568Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/HMM_CRF/</loc><lastmod>2025-12-02T14:46:35.568Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/TNER-复旦为什么TRM在NER上效果差/</loc><lastmod>2025-12-02T14:46:35.572Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/autoner/</loc><lastmod>2025-12-02T14:46:35.572Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/命名体识别资源梳理（代码+博客讲解）/</loc><lastmod>2025-12-02T14:46:35.575Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/工业级命名体识别的做法/</loc><lastmod>2025-12-02T14:46:35.575Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/词典匹配+模型预测-实体识别两大法宝/</loc><lastmod>2025-12-02T14:46:35.575Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/复盘多模态需要解决的6个问题/</loc><lastmod>2025-12-02T14:46:35.575Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/多模态中各种Fusion方式汇总/</loc><lastmod>2025-12-02T14:46:35.575Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/多模态之ViLBERT：双流网络，各自为王/</loc><lastmod>2025-12-02T14:46:35.575Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/多模态资源汇总/</loc><lastmod>2025-12-02T14:46:35.575Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/如何将多模态数据融入到BERT架构中-多模态BERT的两类预训练任务/</loc><lastmod>2025-12-02T14:46:35.575Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/层次体系的构建-多模态解析/</loc><lastmod>2025-12-02T14:46:35.575Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/层次分类体系的必要性-多模态讲解系列/</loc><lastmod>2025-12-02T14:46:35.575Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/文本和图像特征表示模块详解-多模态讲解系列/</loc><lastmod>2025-12-02T14:46:35.575Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/对比学习/Moco1论文解析/</loc><lastmod>2025-12-02T14:46:35.575Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/ACL2020-多任务负监督方式增加CLS表达差异性/</loc><lastmod>2025-12-02T14:46:35.575Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/CNN文本分类解读/</loc><lastmod>2025-12-02T14:46:35.576Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/LCM-缓解标签不独立以及标注错误的问题/</loc><lastmod>2025-12-02T14:46:35.578Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/README/</loc><lastmod>2025-12-02T14:46:35.581Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/UDA/</loc><lastmod>2025-12-02T14:46:35.584Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/关键词信息如何融入到文本分类任务中/</loc><lastmod>2025-12-02T14:46:35.591Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/半监督入门思想之伪标签/</loc><lastmod>2025-12-02T14:46:35.591Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/只使用标签名称就可以文本分类/</loc><lastmod>2025-12-02T14:46:35.591Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/在文本分类上微调Bert/</loc><lastmod>2025-12-02T14:46:35.591Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/文本分类资源总结/</loc><lastmod>2025-12-02T14:46:35.593Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/DSSM论文-公司实战文章/</loc><lastmod>2025-12-02T14:46:35.593Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/ESIM/</loc><lastmod>2025-12-02T14:46:35.593Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/SIMCSE论文解析/</loc><lastmod>2025-12-02T14:46:35.598Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/bert白化简单的梳理/</loc><lastmod>2025-12-02T14:46:35.598Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/五千字全面梳理文本相似度和文本匹配模型/</loc><lastmod>2025-12-02T14:46:35.599Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/聊一下孪生网络和DSSM的混淆点以及向量召回的一个细节/</loc><lastmod>2025-12-02T14:46:35.599Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/阿里RE2-将残差连接和文本匹配模型融合/</loc><lastmod>2025-12-02T14:46:35.599Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本纠错/文本纠错资源总结/</loc><lastmod>2025-12-02T14:46:35.601Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/README/</loc><lastmod>2025-12-02T14:46:35.610Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/bpe-subword论文的我的阅读总结/</loc><lastmod>2025-12-02T14:46:35.610Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/BERT知识蒸馏代码解析-如何写好损失函数/</loc><lastmod>2025-12-02T14:46:35.610Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/Bert蒸馏到简单网络lstm/</loc><lastmod>2025-12-02T14:46:35.610Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/Theseus-模块压缩交替训练/</loc><lastmod>2025-12-02T14:46:35.612Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/bert2textcnn模型蒸馏/</loc><lastmod>2025-12-02T14:46:35.612Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/tinybert-全方位蒸馏/</loc><lastmod>2025-12-02T14:46:35.621Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/PKD-Bert基于多层的知识蒸馏方式/</loc><lastmod>2025-12-02T14:46:35.612Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/什么是知识蒸馏/</loc><lastmod>2025-12-02T14:46:35.625Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/知识蒸馏综述万字长文/</loc><lastmod>2025-12-02T14:46:35.625Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/论文解读/模型训练需不需要将损失降低为零/</loc><lastmod>2025-12-02T14:46:35.625Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/CBOW和skip-gram相较而言，彼此相对适合哪些场景/</loc><lastmod>2025-12-02T14:46:35.625Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/Fasttext解读1/</loc><lastmod>2025-12-02T14:46:35.626Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/README/</loc><lastmod>2025-12-02T14:46:35.626Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/Fasttext解读2/</loc><lastmod>2025-12-02T14:46:35.626Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/Word2vec为什么需要二次采样？/</loc><lastmod>2025-12-02T14:46:35.626Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/Word2vec模型究竟是如何获得词向量的/</loc><lastmod>2025-12-02T14:46:35.626Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/Word2vec的负采样/</loc><lastmod>2025-12-02T14:46:35.626Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/Word2vec训练参数的选定/</loc><lastmod>2025-12-02T14:46:35.626Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/word2vec两种优化方式的联系和区别/</loc><lastmod>2025-12-02T14:46:35.626Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/史上最全词向量面试题梳理/</loc><lastmod>2025-12-02T14:46:35.626Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/聊一下Glove/</loc><lastmod>2025-12-02T14:46:35.627Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/聊一下Word2vec-模型篇/</loc><lastmod>2025-12-02T14:46:35.627Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/聊一下Word2vec-细节篇/</loc><lastmod>2025-12-02T14:46:35.627Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/聊一下Word2vec-训练优化篇/</loc><lastmod>2025-12-02T14:46:35.627Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/词向量/</loc><lastmod>2025-12-02T14:46:35.627Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/词向量资源总结/</loc><lastmod>2025-12-02T14:46:35.627Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.007Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.011Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.011Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.011Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.011Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.011Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.012Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/src/ESIM-attention/ESIM代码解读/</loc><lastmod>2025-12-02T14:46:35.506Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.512Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.512Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.512Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.512Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/tools/README/</loc><lastmod>2025-12-02T14:46:35.522Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/关键词提取/中文分词/基于词典的正向最大匹配和逆向最大匹配中文分词/</loc><lastmod>2025-12-02T14:46:35.563Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/CHANGELOG/</loc><lastmod>2025-12-02T14:46:35.601Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/CONTRIBUTING/</loc><lastmod>2025-12-02T14:46:35.601Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/LICENSE/</loc><lastmod>2025-12-02T14:46:35.601Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/README/</loc><lastmod>2025-12-02T14:46:35.601Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/README_old/</loc><lastmod>2025-12-02T14:46:35.601Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.603Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/CONTRIBUTING/</loc><lastmod>2025-12-02T14:46:35.512Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/FAQ/</loc><lastmod>2025-12-02T14:46:35.513Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/Library/</loc><lastmod>2025-12-02T14:46:35.513Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/Summarization/</loc><lastmod>2025-12-02T14:46:35.513Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/extended/</loc><lastmod>2025-12-02T14:46:35.513Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/im2text/</loc><lastmod>2025-12-02T14:46:35.513Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/</loc><lastmod>2025-12-02T14:46:35.513Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/main/</loc><lastmod>2025-12-02T14:46:35.513Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/quickstart/</loc><lastmod>2025-12-02T14:46:35.514Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/speech2text/</loc><lastmod>2025-12-02T14:46:35.514Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/src/ESIM-attention/ESIM代码解读/</loc><lastmod>2025-12-02T14:46:35.598Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.601Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.602Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.602Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.602Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/tools/README/</loc><lastmod>2025-12-02T14:46:35.608Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/CONTRIBUTING/</loc><lastmod>2025-12-02T14:46:35.602Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/FAQ/</loc><lastmod>2025-12-02T14:46:35.602Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/Library/</loc><lastmod>2025-12-02T14:46:35.602Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/Summarization/</loc><lastmod>2025-12-02T14:46:35.602Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/extended/</loc><lastmod>2025-12-02T14:46:35.602Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/im2text/</loc><lastmod>2025-12-02T14:46:35.602Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/</loc><lastmod>2025-12-02T14:46:35.602Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/main/</loc><lastmod>2025-12-02T14:46:35.602Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/quickstart/</loc><lastmod>2025-12-02T14:46:35.603Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/speech2text/</loc><lastmod>2025-12-02T14:46:35.603Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:46:35.016Z</lastmod></url></urlset>