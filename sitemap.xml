<?xml version="1.0" encoding="UTF-8"?><urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"><url><loc>http://www.ephesus.top/2025/win10_4.2_BSD/</loc><lastmod>2025-12-02T14:37:31.177Z</lastmod></url><url><loc>http://www.ephesus.top/2024/in_decline/</loc><lastmod>2025-12-02T14:37:31.177Z</lastmod></url><url><loc>http://www.ephesus.top/2024/lunch_in_the_library/</loc><lastmod>2025-12-02T14:37:31.177Z</lastmod></url><url><loc>http://www.ephesus.top/2024/dejavu/</loc><lastmod>2025-12-02T14:37:31.176Z</lastmod></url><url><loc>http://www.ephesus.top/2024/dwarfs_best_friend/</loc><lastmod>2025-12-02T14:37:31.177Z</lastmod></url><url><loc>http://www.ephesus.top/2024/man_behind_curtain/</loc><lastmod>2025-12-02T14:37:31.177Z</lastmod></url><url><loc>http://www.ephesus.top/2024/magma/</loc><lastmod>2025-12-02T14:37:31.177Z</lastmod></url><url><loc>http://www.ephesus.top/2024/practice_and_atmospheric/</loc><lastmod>2025-12-02T14:37:31.177Z</lastmod></url><url><loc>http://www.ephesus.top/2024/foocubus/</loc><lastmod>2025-12-02T14:37:31.177Z</lastmod></url><url><loc>http://www.ephesus.top/2024/demogorgon_patch_4/</loc><lastmod>2025-12-02T14:37:31.176Z</lastmod></url><url><loc>http://www.ephesus.top/2024/demogorgon_patch_3/</loc><lastmod>2025-12-02T14:37:31.176Z</lastmod></url><url><loc>http://www.ephesus.top/2024/demogorgon_patch_2/</loc><lastmod>2025-12-02T14:37:31.176Z</lastmod></url><url><loc>http://www.ephesus.top/2024/BoMENet-arc/</loc><lastmod>2025-12-02T14:37:31.176Z</lastmod></url><url><loc>http://www.ephesus.top/2024/Avanor/</loc><lastmod>2025-12-02T14:37:31.175Z</lastmod></url><url><loc>http://www.ephesus.top/2023/demogorgon_patch_1/</loc><lastmod>2025-12-02T14:37:31.176Z</lastmod></url><url><loc>http://www.ephesus.top/2023/ChatGPT-receipt/</loc><lastmod>2025-12-02T14:37:31.176Z</lastmod></url><url><loc>http://www.ephesus.top/2022/another_yasd/</loc><lastmod>2025-12-02T14:37:31.176Z</lastmod></url><url><loc>http://www.ephesus.top/2022/just_readme/</loc><lastmod>2025-12-02T14:37:31.177Z</lastmod></url><url><loc>http://www.ephesus.top/about/</loc><lastmod>2025-12-02T14:37:31.177Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:31.180Z</lastmod></url><url><loc>http://www.ephesus.top/links/</loc><lastmod>2025-12-02T14:37:33.087Z</lastmod></url><url><loc>http://www.ephesus.top/roguelike/</loc><lastmod>2025-12-02T14:37:33.088Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/</loc><lastmod>2025-12-02T14:37:32.020Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/</loc><lastmod>2025-12-02T14:37:32.897Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Cheat/</loc><lastmod>2025-12-02T14:37:31.244Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/</loc><lastmod>2025-12-02T14:37:31.366Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/IMG Dos/</loc><lastmod>2025-12-02T14:37:31.395Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Other Platform/</loc><lastmod>2025-12-02T14:37:32.005Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Picture/</loc><lastmod>2025-12-02T14:37:32.013Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Scenario/</loc><lastmod>2025-12-02T14:37:32.017Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Sound/</loc><lastmod>2025-12-02T14:37:32.018Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Update/</loc><lastmod>2025-12-02T14:37:32.019Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Win/</loc><lastmod>2025-12-02T14:37:32.020Z</lastmod></url><url><loc>http://www.ephesus.top/files/Avanor/Avanor/</loc><lastmod>2025-12-02T14:37:31.192Z</lastmod></url><url><loc>http://www.ephesus.top/files/tomenet/BoMENet-arc/</loc><lastmod>2025-12-02T14:37:32.589Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch中mask是如何实现的代码版本1-阅读文本相似度模型/</loc><lastmod>2025-12-02T14:37:32.897Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch修改ESIM代码中mask矩阵查看效果-效果一般/</loc><lastmod>2025-12-02T14:37:32.897Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/README/</loc><lastmod>2025-12-02T14:37:32.897Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/pytorch处理文本数据代码版本1-处理文本相似度数据/</loc><lastmod>2025-12-02T14:37:32.897Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/pytorch处理文本数据代码版本2-处理文本相似度数据/</loc><lastmod>2025-12-02T14:37:32.897Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/pytorch对text数据的预处理-综述/</loc><lastmod>2025-12-02T14:37:32.897Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/FM/</loc><lastmod>2025-12-02T14:37:32.897Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/deepfm/</loc><lastmod>2025-12-02T14:37:32.899Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/推荐资源更新/</loc><lastmod>2025-12-02T14:37:32.910Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/搜索/倒排索引基本概念/</loc><lastmod>2025-12-02T14:37:32.910Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_474_01/</loc><lastmod>2025-12-02T14:37:31.260Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/搜索/搜索资源总结-持续更新/</loc><lastmod>2025-12-02T14:37:32.910Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_474_03/</loc><lastmod>2025-12-02T14:37:31.275Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_474_04/</loc><lastmod>2025-12-02T14:37:31.289Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_474_05/</loc><lastmod>2025-12-02T14:37:31.303Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_474_05Fr/</loc><lastmod>2025-12-02T14:37:31.317Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_475_01/</loc><lastmod>2025-12-02T14:37:31.334Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/IMG Dos/IMG_474_01/</loc><lastmod>2025-12-02T14:37:31.387Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/IMG Dos/IMG_474_04/</loc><lastmod>2025-12-02T14:37:31.390Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_475_02G/</loc><lastmod>2025-12-02T14:37:31.366Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Dos/CIV_475_01Rus/</loc><lastmod>2025-12-02T14:37:31.351Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/IMG Dos/IMG_475_01/</loc><lastmod>2025-12-02T14:37:31.393Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/IMG Dos/IMG_475_02G/</loc><lastmod>2025-12-02T14:37:31.395Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Scenario/JustForWin/</loc><lastmod>2025-12-02T14:37:32.015Z</lastmod></url><url><loc>http://www.ephesus.top/files/hxh_civ/Update/PowerMac Fix/</loc><lastmod>2025-12-02T14:37:32.019Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.461Z</lastmod></url><url><loc>http://www.ephesus.top/files/rl/emeraldwoods/web/</loc><lastmod>2025-12-02T14:37:32.461Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.466Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.466Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.466Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch/Pytorch中mask是如何实现的代码版本1-阅读文本相似度模型/</loc><lastmod>2025-12-02T14:37:32.897Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch/Pytorch修改ESIM代码中mask矩阵查看效果-效果一般/</loc><lastmod>2025-12-02T14:37:32.897Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch/pytorch处理文本数据代码版本1-处理文本相似度数据/</loc><lastmod>2025-12-02T14:37:32.897Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch/README/</loc><lastmod>2025-12-02T14:37:32.897Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch/pytorch处理文本数据代码版本2-处理文本相似度数据/</loc><lastmod>2025-12-02T14:37:32.897Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/Pytorch/Pytorch/pytorch对text数据的预处理-综述/</loc><lastmod>2025-12-02T14:37:32.897Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/WDL/WDL在贝壳中的应用实践总结/</loc><lastmod>2025-12-02T14:37:32.899Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/WDL/WDl/</loc><lastmod>2025-12-02T14:37:32.899Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/推荐/FM/</loc><lastmod>2025-12-02T14:37:32.904Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/推荐/deepfm/</loc><lastmod>2025-12-02T14:37:32.905Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/推荐/推荐资源更新/</loc><lastmod>2025-12-02T14:37:32.910Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/搜索/搜索/倒排索引基本概念/</loc><lastmod>2025-12-02T14:37:32.910Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/搜索/搜索/搜索资源总结-持续更新/</loc><lastmod>2025-12-02T14:37:32.910Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/ALBERT-更小更少但并不快/</loc><lastmod>2025-12-02T14:37:32.910Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/Bert各种后续预训练模型-预训练模型的改进/</loc><lastmod>2025-12-02T14:37:32.912Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/Bert如何融入知识一-百度和清华ERINE/</loc><lastmod>2025-12-02T14:37:32.912Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/Bert如何融入知识二-Bert融合知识图谱/</loc><lastmod>2025-12-02T14:37:32.912Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/Bert的可视化-Bert每一层都学到了什么/</loc><lastmod>2025-12-02T14:37:32.912Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/Bert资源总结/</loc><lastmod>2025-12-02T14:37:32.912Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/FastBert/</loc><lastmod>2025-12-02T14:37:32.912Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/Pytorch代码分析-如何让Bert在finetune小数据集时更“稳”一点/</loc><lastmod>2025-12-02T14:37:32.913Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/RoBERTa/</loc><lastmod>2025-12-02T14:37:32.913Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/UniLM/</loc><lastmod>2025-12-02T14:37:32.916Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/XLNET/</loc><lastmod>2025-12-02T14:37:32.916Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/tBERT-BERT融合主题模型/</loc><lastmod>2025-12-02T14:37:32.920Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/为什么Bert做不好无监督语义匹配/</loc><lastmod>2025-12-02T14:37:32.922Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/如何在脱敏数据中使用BERT等预训练模型/</loc><lastmod>2025-12-02T14:37:32.922Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/解决老大难问题-如何一行代码带你随心所欲重新初始化bert的某些参数附Pytorch代码/</loc><lastmod>2025-12-02T14:37:32.922Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/3分钟从零解读Transformer的Encoder/</loc><lastmod>2025-12-02T14:37:32.922Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/BN踩坑记--谈一下Batch Normalization的优缺点和适用场景/</loc><lastmod>2025-12-02T14:37:32.922Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/NLP任务中-layer-norm比BatchNorm好在哪里/</loc><lastmod>2025-12-02T14:37:32.922Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/Transformer的并行化/</loc><lastmod>2025-12-02T14:37:32.923Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/Transformer面试题全部答案解析合辑/</loc><lastmod>2025-12-02T14:37:32.923Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/VIT-如何将Transformer更好的应用到CV领域/</loc><lastmod>2025-12-02T14:37:32.923Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/transformer-bert资源总结/</loc><lastmod>2025-12-02T14:37:32.929Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/transformer资源总结/</loc><lastmod>2025-12-02T14:37:32.929Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/原版Transformer的位置编码究竟有没有包含相对位置信息/</loc><lastmod>2025-12-02T14:37:32.929Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/史上最全Transformer面试题/</loc><lastmod>2025-12-02T14:37:32.929Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/答案合辑/</loc><lastmod>2025-12-02T14:37:32.929Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/答案解析—史上最全Transformer面试题：灵魂20问帮你彻底搞定Transformer/</loc><lastmod>2025-12-02T14:37:32.929Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/谈一下相对位置编码/</loc><lastmod>2025-12-02T14:37:32.930Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Transformer/谈一谈Decoder模块/</loc><lastmod>2025-12-02T14:37:32.930Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/关键词提取/README/</loc><lastmod>2025-12-02T14:37:32.931Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/关键词提取/关键词提取资源总结/</loc><lastmod>2025-12-02T14:37:32.932Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/关键词提取/关键词提取方法综述/</loc><lastmod>2025-12-02T14:37:32.932Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/关键词提取/实体库构建：大规模离线新词实体挖掘/</loc><lastmod>2025-12-02T14:37:32.932Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/其他/20201210一周技术问题答疑汇总/</loc><lastmod>2025-12-02T14:37:32.932Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/其他/RNN的梯度消失有什么与众不同的地方/</loc><lastmod>2025-12-02T14:37:32.932Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/句向量/README/</loc><lastmod>2025-12-02T14:37:32.932Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/句向量/句向量模型综述/</loc><lastmod>2025-12-02T14:37:32.933Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/FLAT-Transformer/</loc><lastmod>2025-12-02T14:37:32.934Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/HMM_CRF/</loc><lastmod>2025-12-02T14:37:32.936Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/README/</loc><lastmod>2025-12-02T14:37:32.936Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/TNER-复旦为什么TRM在NER上效果差/</loc><lastmod>2025-12-02T14:37:32.940Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/autoner/</loc><lastmod>2025-12-02T14:37:32.940Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/命名体识别资源梳理（代码+博客讲解）/</loc><lastmod>2025-12-02T14:37:32.943Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/工业级命名体识别的做法/</loc><lastmod>2025-12-02T14:37:32.943Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/词典匹配+模型预测-实体识别两大法宝/</loc><lastmod>2025-12-02T14:37:32.943Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/复盘多模态需要解决的6个问题/</loc><lastmod>2025-12-02T14:37:32.944Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/多模态中各种Fusion方式汇总/</loc><lastmod>2025-12-02T14:37:32.944Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/多模态之ViLBERT：双流网络，各自为王/</loc><lastmod>2025-12-02T14:37:32.944Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/多模态资源汇总/</loc><lastmod>2025-12-02T14:37:32.944Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/如何将多模态数据融入到BERT架构中-多模态BERT的两类预训练任务/</loc><lastmod>2025-12-02T14:37:32.944Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/层次体系的构建-多模态解析/</loc><lastmod>2025-12-02T14:37:32.944Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/层次分类体系的必要性-多模态讲解系列/</loc><lastmod>2025-12-02T14:37:32.944Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/多模态/文本和图像特征表示模块详解-多模态讲解系列/</loc><lastmod>2025-12-02T14:37:32.944Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/对比学习/Moco1论文解析/</loc><lastmod>2025-12-02T14:37:32.944Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/ACL2020-多任务负监督方式增加CLS表达差异性/</loc><lastmod>2025-12-02T14:37:32.944Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/CNN文本分类解读/</loc><lastmod>2025-12-02T14:37:32.944Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/LCM-缓解标签不独立以及标注错误的问题/</loc><lastmod>2025-12-02T14:37:32.946Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/README/</loc><lastmod>2025-12-02T14:37:32.949Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/UDA/</loc><lastmod>2025-12-02T14:37:32.953Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/关键词信息如何融入到文本分类任务中/</loc><lastmod>2025-12-02T14:37:32.960Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/半监督入门思想之伪标签/</loc><lastmod>2025-12-02T14:37:32.960Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/只使用标签名称就可以文本分类/</loc><lastmod>2025-12-02T14:37:32.960Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/在文本分类上微调Bert/</loc><lastmod>2025-12-02T14:37:32.960Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/文本分类资源总结/</loc><lastmod>2025-12-02T14:37:32.962Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本纠错/文本纠错资源总结/</loc><lastmod>2025-12-02T14:37:32.970Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/DSSM论文-公司实战文章/</loc><lastmod>2025-12-02T14:37:32.962Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/ESIM/</loc><lastmod>2025-12-02T14:37:32.962Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/SIMCSE论文解析/</loc><lastmod>2025-12-02T14:37:32.967Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/bert白化简单的梳理/</loc><lastmod>2025-12-02T14:37:32.967Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/五千字全面梳理文本相似度和文本匹配模型/</loc><lastmod>2025-12-02T14:37:32.967Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/阿里RE2-将残差连接和文本匹配模型融合/</loc><lastmod>2025-12-02T14:37:32.968Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/聊一下孪生网络和DSSM的混淆点以及向量召回的一个细节/</loc><lastmod>2025-12-02T14:37:32.968Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/README/</loc><lastmod>2025-12-02T14:37:32.979Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/bpe-subword论文的我的阅读总结/</loc><lastmod>2025-12-02T14:37:32.979Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/BERT知识蒸馏代码解析-如何写好损失函数/</loc><lastmod>2025-12-02T14:37:32.979Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/Bert蒸馏到简单网络lstm/</loc><lastmod>2025-12-02T14:37:32.979Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/PKD-Bert基于多层的知识蒸馏方式/</loc><lastmod>2025-12-02T14:37:32.982Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/Theseus-模块压缩交替训练/</loc><lastmod>2025-12-02T14:37:32.982Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/bert2textcnn模型蒸馏/</loc><lastmod>2025-12-02T14:37:32.982Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/tinybert-全方位蒸馏/</loc><lastmod>2025-12-02T14:37:32.990Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/什么是知识蒸馏/</loc><lastmod>2025-12-02T14:37:32.995Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/模型蒸馏/知识蒸馏综述万字长文/</loc><lastmod>2025-12-02T14:37:32.995Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/论文解读/模型训练需不需要将损失降低为零/</loc><lastmod>2025-12-02T14:37:33.085Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/CBOW和skip-gram相较而言，彼此相对适合哪些场景/</loc><lastmod>2025-12-02T14:37:33.085Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/Fasttext解读2/</loc><lastmod>2025-12-02T14:37:33.085Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/Fasttext解读1/</loc><lastmod>2025-12-02T14:37:33.085Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/README/</loc><lastmod>2025-12-02T14:37:33.086Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/Word2vec为什么需要二次采样？/</loc><lastmod>2025-12-02T14:37:33.086Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/Word2vec模型究竟是如何获得词向量的/</loc><lastmod>2025-12-02T14:37:33.086Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/Word2vec的负采样/</loc><lastmod>2025-12-02T14:37:33.086Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/Word2vec训练参数的选定/</loc><lastmod>2025-12-02T14:37:33.086Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/word2vec两种优化方式的联系和区别/</loc><lastmod>2025-12-02T14:37:33.087Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/史上最全词向量面试题梳理/</loc><lastmod>2025-12-02T14:37:33.087Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/聊一下Glove/</loc><lastmod>2025-12-02T14:37:33.087Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/聊一下Word2vec-模型篇/</loc><lastmod>2025-12-02T14:37:33.087Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/聊一下Word2vec-细节篇/</loc><lastmod>2025-12-02T14:37:33.087Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/聊一下Word2vec-训练优化篇/</loc><lastmod>2025-12-02T14:37:33.087Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/词向量/</loc><lastmod>2025-12-02T14:37:33.087Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/词向量/词向量资源总结/</loc><lastmod>2025-12-02T14:37:33.087Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.459Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.459Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.459Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.459Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.459Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.459Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.459Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.460Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.460Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.460Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.460Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.460Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.461Z</lastmod></url><url><loc>http://www.ephesus.top/files/rl/omega/JSOmega/JSomega/</loc><lastmod>2025-12-02T14:37:32.529Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/推荐/WDL/WDL在贝壳中的应用实践总结/</loc><lastmod>2025-12-02T14:37:32.905Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/推荐/推荐/WDL/WDl/</loc><lastmod>2025-12-02T14:37:32.905Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/关键词提取/中文分词/基于词典的正向最大匹配和逆向最大匹配中文分词/</loc><lastmod>2025-12-02T14:37:32.932Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/CHANGELOG/</loc><lastmod>2025-12-02T14:37:32.970Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/CONTRIBUTING/</loc><lastmod>2025-12-02T14:37:32.970Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/LICENSE/</loc><lastmod>2025-12-02T14:37:32.970Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/README/</loc><lastmod>2025-12-02T14:37:32.970Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/README_old/</loc><lastmod>2025-12-02T14:37:32.970Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.972Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/ALBERT-更小更少但并不快/</loc><lastmod>2025-12-02T14:37:32.995Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/Bert如何融入知识一-百度和清华ERINE/</loc><lastmod>2025-12-02T14:37:32.996Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/Bert各种后续预训练模型-预训练模型的改进/</loc><lastmod>2025-12-02T14:37:32.996Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/Bert如何融入知识二-Bert融合知识图谱/</loc><lastmod>2025-12-02T14:37:32.996Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/Bert资源总结/</loc><lastmod>2025-12-02T14:37:32.996Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/Bert的可视化-Bert每一层都学到了什么/</loc><lastmod>2025-12-02T14:37:32.996Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/FastBert/</loc><lastmod>2025-12-02T14:37:32.996Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/Pytorch代码分析-如何让Bert在finetune小数据集时更“稳”一点/</loc><lastmod>2025-12-02T14:37:32.998Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/RoBERTa/</loc><lastmod>2025-12-02T14:37:32.998Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/UniLM/</loc><lastmod>2025-12-02T14:37:33.000Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/XLNET/</loc><lastmod>2025-12-02T14:37:33.000Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/tBERT-BERT融合主题模型/</loc><lastmod>2025-12-02T14:37:33.005Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/为什么Bert做不好无监督语义匹配/</loc><lastmod>2025-12-02T14:37:33.007Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/如何在脱敏数据中使用BERT等预训练模型/</loc><lastmod>2025-12-02T14:37:33.007Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Bert/解决老大难问题-如何一行代码带你随心所欲重新初始化bert的某些参数附Pytorch代码/</loc><lastmod>2025-12-02T14:37:33.007Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/3分钟从零解读Transformer的Encoder/</loc><lastmod>2025-12-02T14:37:33.007Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/BN踩坑记--谈一下Batch Normalization的优缺点和适用场景/</loc><lastmod>2025-12-02T14:37:33.007Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/NLP任务中-layer-norm比BatchNorm好在哪里/</loc><lastmod>2025-12-02T14:37:33.007Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/Transformer的并行化/</loc><lastmod>2025-12-02T14:37:33.007Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/Transformer面试题全部答案解析合辑/</loc><lastmod>2025-12-02T14:37:33.007Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/VIT-如何将Transformer更好的应用到CV领域/</loc><lastmod>2025-12-02T14:37:33.007Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/transformer-bert资源总结/</loc><lastmod>2025-12-02T14:37:33.013Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/transformer资源总结/</loc><lastmod>2025-12-02T14:37:33.013Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/原版Transformer的位置编码究竟有没有包含相对位置信息/</loc><lastmod>2025-12-02T14:37:33.013Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/史上最全Transformer面试题/</loc><lastmod>2025-12-02T14:37:33.014Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/答案合辑/</loc><lastmod>2025-12-02T14:37:33.014Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/答案解析—史上最全Transformer面试题：灵魂20问帮你彻底搞定Transformer/</loc><lastmod>2025-12-02T14:37:33.014Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/谈一下相对位置编码/</loc><lastmod>2025-12-02T14:37:33.014Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/谈一谈Decoder模块/</loc><lastmod>2025-12-02T14:37:33.014Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/关键词提取/README/</loc><lastmod>2025-12-02T14:37:33.014Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/关键词提取/关键词提取方法综述/</loc><lastmod>2025-12-02T14:37:33.014Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/关键词提取/关键词提取资源总结/</loc><lastmod>2025-12-02T14:37:33.014Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/关键词提取/实体库构建：大规模离线新词实体挖掘/</loc><lastmod>2025-12-02T14:37:33.014Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/其他/20201210一周技术问题答疑汇总/</loc><lastmod>2025-12-02T14:37:33.014Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/其他/RNN的梯度消失有什么与众不同的地方/</loc><lastmod>2025-12-02T14:37:33.014Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/句向量/句向量模型综述/</loc><lastmod>2025-12-02T14:37:33.016Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/句向量/README/</loc><lastmod>2025-12-02T14:37:33.015Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/HMM_CRF/</loc><lastmod>2025-12-02T14:37:33.019Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/FLAT-Transformer/</loc><lastmod>2025-12-02T14:37:33.016Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/README/</loc><lastmod>2025-12-02T14:37:33.019Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/TNER-复旦为什么TRM在NER上效果差/</loc><lastmod>2025-12-02T14:37:33.023Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/autoner/</loc><lastmod>2025-12-02T14:37:33.023Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/命名体识别资源梳理（代码+博客讲解）/</loc><lastmod>2025-12-02T14:37:33.026Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/工业级命名体识别的做法/</loc><lastmod>2025-12-02T14:37:33.026Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/命名体识别/词典匹配+模型预测-实体识别两大法宝/</loc><lastmod>2025-12-02T14:37:33.026Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/复盘多模态需要解决的6个问题/</loc><lastmod>2025-12-02T14:37:33.026Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/多模态中各种Fusion方式汇总/</loc><lastmod>2025-12-02T14:37:33.027Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/多模态之ViLBERT：双流网络，各自为王/</loc><lastmod>2025-12-02T14:37:33.027Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/多模态资源汇总/</loc><lastmod>2025-12-02T14:37:33.027Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/如何将多模态数据融入到BERT架构中-多模态BERT的两类预训练任务/</loc><lastmod>2025-12-02T14:37:33.027Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/层次分类体系的必要性-多模态讲解系列/</loc><lastmod>2025-12-02T14:37:33.027Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/文本和图像特征表示模块详解-多模态讲解系列/</loc><lastmod>2025-12-02T14:37:33.027Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/对比学习/Moco1论文解析/</loc><lastmod>2025-12-02T14:37:33.027Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/多模态/层次体系的构建-多模态解析/</loc><lastmod>2025-12-02T14:37:33.027Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/ACL2020-多任务负监督方式增加CLS表达差异性/</loc><lastmod>2025-12-02T14:37:33.027Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/CNN文本分类解读/</loc><lastmod>2025-12-02T14:37:33.027Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/LCM-缓解标签不独立以及标注错误的问题/</loc><lastmod>2025-12-02T14:37:33.029Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/README/</loc><lastmod>2025-12-02T14:37:33.032Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/UDA/</loc><lastmod>2025-12-02T14:37:33.036Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/关键词信息如何融入到文本分类任务中/</loc><lastmod>2025-12-02T14:37:33.043Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/半监督入门思想之伪标签/</loc><lastmod>2025-12-02T14:37:33.043Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/只使用标签名称就可以文本分类/</loc><lastmod>2025-12-02T14:37:33.043Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/在文本分类上微调Bert/</loc><lastmod>2025-12-02T14:37:33.043Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/文本分类资源总结/</loc><lastmod>2025-12-02T14:37:33.045Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/DSSM论文-公司实战文章/</loc><lastmod>2025-12-02T14:37:33.045Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/ESIM/</loc><lastmod>2025-12-02T14:37:33.045Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/SIMCSE论文解析/</loc><lastmod>2025-12-02T14:37:33.050Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/bert白化简单的梳理/</loc><lastmod>2025-12-02T14:37:33.050Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/聊一下孪生网络和DSSM的混淆点以及向量召回的一个细节/</loc><lastmod>2025-12-02T14:37:33.051Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/五千字全面梳理文本相似度和文本匹配模型/</loc><lastmod>2025-12-02T14:37:33.051Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/阿里RE2-将残差连接和文本匹配模型融合/</loc><lastmod>2025-12-02T14:37:33.051Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本纠错/文本纠错资源总结/</loc><lastmod>2025-12-02T14:37:33.054Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/README/</loc><lastmod>2025-12-02T14:37:33.064Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/bpe-subword论文的我的阅读总结/</loc><lastmod>2025-12-02T14:37:33.064Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/BERT知识蒸馏代码解析-如何写好损失函数/</loc><lastmod>2025-12-02T14:37:33.064Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/Bert蒸馏到简单网络lstm/</loc><lastmod>2025-12-02T14:37:33.064Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/PKD-Bert基于多层的知识蒸馏方式/</loc><lastmod>2025-12-02T14:37:33.067Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/Theseus-模块压缩交替训练/</loc><lastmod>2025-12-02T14:37:33.067Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/bert2textcnn模型蒸馏/</loc><lastmod>2025-12-02T14:37:33.067Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/tinybert-全方位蒸馏/</loc><lastmod>2025-12-02T14:37:33.078Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/什么是知识蒸馏/</loc><lastmod>2025-12-02T14:37:33.083Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/模型蒸馏/知识蒸馏综述万字长文/</loc><lastmod>2025-12-02T14:37:33.083Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/论文解读/模型训练需不需要将损失降低为零/</loc><lastmod>2025-12-02T14:37:33.083Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/CBOW和skip-gram相较而言，彼此相对适合哪些场景/</loc><lastmod>2025-12-02T14:37:33.083Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/Fasttext解读1/</loc><lastmod>2025-12-02T14:37:33.083Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/Fasttext解读2/</loc><lastmod>2025-12-02T14:37:33.083Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/README/</loc><lastmod>2025-12-02T14:37:33.083Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/Word2vec为什么需要二次采样？/</loc><lastmod>2025-12-02T14:37:33.084Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/Word2vec模型究竟是如何获得词向量的/</loc><lastmod>2025-12-02T14:37:33.084Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/Word2vec的负采样/</loc><lastmod>2025-12-02T14:37:33.084Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/Word2vec训练参数的选定/</loc><lastmod>2025-12-02T14:37:33.084Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/word2vec两种优化方式的联系和区别/</loc><lastmod>2025-12-02T14:37:33.085Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/史上最全词向量面试题梳理/</loc><lastmod>2025-12-02T14:37:33.085Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/聊一下Word2vec-模型篇/</loc><lastmod>2025-12-02T14:37:33.085Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/聊一下Glove/</loc><lastmod>2025-12-02T14:37:33.085Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/聊一下Word2vec-细节篇/</loc><lastmod>2025-12-02T14:37:33.085Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/聊一下Word2vec-训练优化篇/</loc><lastmod>2025-12-02T14:37:33.085Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/词向量/</loc><lastmod>2025-12-02T14:37:33.085Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/词向量/词向量资源总结/</loc><lastmod>2025-12-02T14:37:33.085Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.466Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.466Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.466Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.466Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.466Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.466Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.461Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/src/ESIM-attention/ESIM代码解读/</loc><lastmod>2025-12-02T14:37:32.967Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.970Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.971Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.971Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.971Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/tools/README/</loc><lastmod>2025-12-02T14:37:32.977Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/关键词提取/中文分词/基于词典的正向最大匹配和逆向最大匹配中文分词/</loc><lastmod>2025-12-02T14:37:33.014Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/CHANGELOG/</loc><lastmod>2025-12-02T14:37:33.054Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/CONTRIBUTING/</loc><lastmod>2025-12-02T14:37:33.054Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/LICENSE/</loc><lastmod>2025-12-02T14:37:33.054Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/README/</loc><lastmod>2025-12-02T14:37:33.054Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/README_old/</loc><lastmod>2025-12-02T14:37:33.054Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:33.056Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/CONTRIBUTING/</loc><lastmod>2025-12-02T14:37:32.971Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/FAQ/</loc><lastmod>2025-12-02T14:37:32.971Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/Library/</loc><lastmod>2025-12-02T14:37:32.971Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/Summarization/</loc><lastmod>2025-12-02T14:37:32.971Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/im2text/</loc><lastmod>2025-12-02T14:37:32.971Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/extended/</loc><lastmod>2025-12-02T14:37:32.971Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/</loc><lastmod>2025-12-02T14:37:32.971Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/main/</loc><lastmod>2025-12-02T14:37:32.971Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/quickstart/</loc><lastmod>2025-12-02T14:37:32.972Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/speech2text/</loc><lastmod>2025-12-02T14:37:32.972Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本匹配和文本相似度/src/ESIM-attention/ESIM代码解读/</loc><lastmod>2025-12-02T14:37:33.051Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:33.054Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:33.054Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:33.054Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:33.054Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/tools/README/</loc><lastmod>2025-12-02T14:37:33.061Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/CONTRIBUTING/</loc><lastmod>2025-12-02T14:37:33.054Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/FAQ/</loc><lastmod>2025-12-02T14:37:33.054Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/Library/</loc><lastmod>2025-12-02T14:37:33.055Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/Summarization/</loc><lastmod>2025-12-02T14:37:33.055Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/extended/</loc><lastmod>2025-12-02T14:37:33.055Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/</loc><lastmod>2025-12-02T14:37:33.055Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/im2text/</loc><lastmod>2025-12-02T14:37:33.055Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/main/</loc><lastmod>2025-12-02T14:37:33.055Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/quickstart/</loc><lastmod>2025-12-02T14:37:33.056Z</lastmod></url><url><loc>http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/机器翻译/OpenNMT-py/docs/source/speech2text/</loc><lastmod>2025-12-02T14:37:33.056Z</lastmod></url><url><loc>undefined</loc><lastmod>2025-12-02T14:37:32.470Z</lastmod></url></urlset>